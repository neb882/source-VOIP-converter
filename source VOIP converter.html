<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VOIP Audio Effect Simulator</title>
    <style>
        body { font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto; padding: 20px; }
        input, button { margin: 10px 0; }
        #status { color: green; }
        #error { color: red; }
    </style>
</head>
<body>
    <h1>VOIP Chat Audio Effect (TF2/CS:S)</h1>
    <p>Upload an MP3 file, and this tool will process it to mimic the older Source Engine VOIP sound: mono, downsampled to 11kHz, tighter band-limiting (high-pass ~100 Hz, low-pass ~4000 Hz), heavier compression to induce clipping, and stronger distortion for artifacts. Preview and download as WAV (convert to MP3 if needed).</p>
    
    <input type="file" id="fileInput" accept="audio/mp3">
    <button id="processBtn">Process Audio</button>
    <p id="status"></p>
    <p id="error"></p>
    
    <audio id="preview" controls></audio>
    <a id="downloadLink" style="display: none;">Download Processed Audio (WAV)</a>

    <script>
        const fileInput = document.getElementById('fileInput');
        const processBtn = document.getElementById('processBtn');
        const status = document.getElementById('status');
        const error = document.getElementById('error');
        const preview = document.getElementById('preview');
        const downloadLink = document.getElementById('downloadLink');

        processBtn.addEventListener('click', async () => {
            const file = fileInput.files[0];
            if (!file) {
                error.textContent = 'Please select an MP3 file.';
                return;
            }
            status.textContent = 'Processing...';
            error.textContent = '';

            try {
                const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
                const arrayBuffer = await file.arrayBuffer();
                const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);

                // Downsample to 11025 Hz for nostalgia (original Source VOIP clamped to ~11kHz)
                const targetSampleRate = 11025;
                const newLength = Math.ceil(audioBuffer.length * targetSampleRate / audioBuffer.sampleRate);
                const offlineCtx = new OfflineAudioContext(1, newLength, targetSampleRate); // Mono, lower sample rate

                // Source node with mono buffer
                const source = offlineCtx.createBufferSource();
                source.buffer = toMono(audioBuffer);

                // High-pass filter (~100 Hz to remove rumble)
                const highpass = offlineCtx.createBiquadFilter();
                highpass.type = 'highpass';
                highpass.frequency.value = 100;
                highpass.Q.value = 1;

                // Low-pass filter (~4000 Hz for narrowband speech)
                const lowpass = offlineCtx.createBiquadFilter();
                lowpass.type = 'lowpass';
                lowpass.frequency.value = 4000;
                lowpass.Q.value = 1;

                // Compressor (more aggressive for clipping)
                const compressor = offlineCtx.createDynamicsCompressor();
                compressor.threshold.value = -12; // Lower threshold for more compression
                compressor.knee.value = 30;
                compressor.ratio.value = 20; // Higher ratio for limiting/clipping
                compressor.attack.value = 0.003;
                compressor.release.value = 0.25;

                // Gain node to boost before distortion (induce more clipping/artifacts)
                const gain = offlineCtx.createGain();
                gain.gain.value = 1.5; // Boost by 3-4 dB

                // Waveshaper for stronger distortion
                const distortion = offlineCtx.createWaveShaper();
                distortion.curve = makeDistortionCurve(3); // Increased amount for grittier sound
                distortion.oversample = '4x';

                // Connect nodes: source -> highpass -> lowpass -> compressor -> gain -> distortion -> destination
                source.connect(highpass);
                highpass.connect(lowpass);
                lowpass.connect(compressor);
                compressor.connect(gain);
                gain.connect(distortion);
                distortion.connect(offlineCtx.destination);

                // Start rendering
                source.start();
                const renderedBuffer = await offlineCtx.startRendering();

                // Preview
                const blob = await audioBufferToWav(renderedBuffer);
                const url = URL.createObjectURL(blob);
                preview.src = url;
                preview.style.display = 'block';

                // Download link
                downloadLink.href = url;
                downloadLink.download = 'processed_voip_nostalgia_audio.wav';
                downloadLink.textContent = 'Download Processed Audio (WAV)';
                downloadLink.style.display = 'block';

                status.textContent = 'Processing complete! Preview below and download.';
            } catch (err) {
                error.textContent = 'Error processing audio: ' + err.message;
                status.textContent = '';
            }
        });

        // Helper: Convert stereo to mono
        function toMono(buffer) {
            if (buffer.numberOfChannels === 1) return buffer;
            const monoBuffer = new AudioBuffer({
                length: buffer.length,
                numberOfChannels: 1,
                sampleRate: buffer.sampleRate
            });
            const left = buffer.getChannelData(0);
            const right = buffer.getChannelData(1);
            const monoData = monoBuffer.getChannelData(0);
            for (let i = 0; i < buffer.length; i++) {
                monoData[i] = (left[i] + right[i]) / 2;
            }
            return monoBuffer;
        }

        // Helper: Create distortion curve
        function makeDistortionCurve(amount) {
            const samples = 44100;
            const curve = new Float32Array(samples);
            const deg = Math.PI / 180;
            for (let i = 0; i < samples; ++i) {
                const x = i * 2 / samples - 1;
                curve[i] = (3 + amount) * x * 20 * deg / (Math.PI + amount * Math.abs(x));
            }
            return curve;
        }

        // Helper: Convert AudioBuffer to WAV Blob
        function audioBufferToWav(buffer) {
            return new Promise((resolve) => {
                const numChannels = buffer.numberOfChannels;
                const sampleRate = buffer.sampleRate;
                const length = buffer.length * numChannels * 2 + 44;
                const wavBuffer = new ArrayBuffer(length);
                const view = new DataView(wavBuffer);

                // RIFF chunk
                writeString(view, 0, 'RIFF');
                view.setUint32(4, 36 + buffer.length * numChannels * 2, true);
                writeString(view, 8, 'WAVE');
                // FMT sub-chunk
                writeString(view, 12, 'fmt ');
                view.setUint32(16, 16, true);
                view.setUint16(20, 1, true); // PCM
                view.setUint16(22, numChannels, true);
                view.setUint32(24, sampleRate, true);
                view.setUint32(28, sampleRate * numChannels * 2, true);
                view.setUint16(32, numChannels * 2, true);
                view.setUint16(34, 16, true); // 16-bit
                // Data sub-chunk
                writeString(view, 36, 'data');
                view.setUint32(40, buffer.length * numChannels * 2, true);

                // Write samples
                let offset = 44;
                for (let i = 0; i < buffer.length; i++) {
                    for (let channel = 0; channel < numChannels; channel++) {
                        const sample = Math.max(-1, Math.min(1, buffer.getChannelData(channel)[i]));
                        view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
                        offset += 2;
                    }
                }

                resolve(new Blob([wavBuffer], { type: 'audio/wav' }));
            });
        }

        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }
    </script>
</body>
</html>