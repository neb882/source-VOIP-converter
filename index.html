<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VOIP Audio Effect Simulator (Opus for CELT)</title>
    <style>
        body { font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto; padding: 20px; }
        input, button { margin: 10px 0; }
        #status { color: green; }
        #error { color: red; }
    </style>
</head>
<body>
    <h1>VOIP Chat Audio Effect (TF2/CS:S with Opus simulating CELT)</h1>
    <p>Upload an MP3 file, and this tool will process it using the Opus codec to mimic later Source Engine VOIP sound: resampled to 24kHz mono, encoded/decoded with Opus for authentic compression artifacts (~22kbps, low-delay mode). Preview and download as WAV.</p>
    
    <input type="file" id="fileInput" accept="audio/mp3">
    <button id="processBtn">Process Audio</button>
    <p id="status"></p>
    <p id="error"></p>
    
    <audio id="preview" controls></audio>
    <a id="downloadLink" style="display: none;">Download Processed Audio (WAV)</a>

    <!-- Include the opus-recorder library (download recorder.min.js and encoderWorker.min.js from https://github.com/chris-rudmin/opus-recorder/tree/master/dist) -->
    <script src="recorder.min.js"></script>

    <script>
        const fileInput = document.getElementById('fileInput');
        const processBtn = document.getElementById('processBtn');
        const status = document.getElementById('status');
        const error = document.getElementById('error');
        const preview = document.getElementById('preview');
        const downloadLink = document.getElementById('downloadLink');

        processBtn.addEventListener('click', async () => {
            const file = fileInput.files[0];
            if (!file) {
                error.textContent = 'Please select an MP3 file.';
                return;
            }
            status.textContent = 'Processing...';
            error.textContent = '';

            try {
                const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
                const arrayBuffer = await file.arrayBuffer();
                const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);

                // Target 24kHz for Opus (close to CELT's 22kHz, Opus supported rate)
                const targetSampleRate = 24000;
                const newLength = Math.ceil(audioBuffer.length * targetSampleRate / audioBuffer.sampleRate);
                const offlineCtx = new OfflineAudioContext(1, newLength, targetSampleRate); // Mono, 24kHz

                const source = offlineCtx.createBufferSource();
                source.buffer = toMono(audioBuffer);

                source.connect(offlineCtx.destination);
                source.start();
                const renderedBuffer = await offlineCtx.startRendering();

                // Get PCM samples as Float32Array
                const samples = renderedBuffer.getChannelData(0);

                // Set up Opus recorder config for CELT-like VOIP (low-delay, ~22kbps)
                const config = {
                    encoderApplication: 2051, // Restricted low-delay (CELT-like)
                    encoderBitRate: 22000,
                    encoderFrameSize: 20, // ms
                    encoderSampleRate: targetSampleRate,
                    encoderPath: 'encoderWorker.min.js',
                    numberOfChannels: 1,
                    streamPages: true // Get data in chunks
                };
                const recorder = new Recorder(config);

                // To encode offline, we simulate 'recording' by manually feeding chunks to the worker
                await recorder.start(); // Initializes the worker

                // Chunk samples into frame size (20ms = 0.02 * 24000 = 480 samples)
                const frameSize = targetSampleRate * 0.02;
                const encodedChunks = [];
                recorder.ondataavailable = (data) => {
                    encodedChunks.push(new Uint8Array(data)); // Collect encoded Opus pages
                };

                // Feed chunks to the internal worker (access via recorder._encoder)
                const worker = recorder._encoder;
                for (let i = 0; i < samples.length; i += frameSize) {
                    const chunk = samples.subarray(i, i + frameSize);
                    if (chunk.length === 0) break;
                    worker.postMessage(chunk); // Send Float32Array to encode
                }

                // Flush and stop
                await recorder.stop();
                recorder.close();

                // Now decode the encoded Opus chunks back to PCM (for simulation)
                // Note: For full round-trip, you'd need a separate decoder worker; here we approximate by using AudioContext decode (if browser supports Opus)
                const encodedBlob = new Blob(encodedChunks, { type: 'audio/opus' });
                const decodedAudioBuffer = await audioCtx.decodeAudioData(await encodedBlob.arrayBuffer());

                // Preview
                const blob = await audioBufferToWav(decodedAudioBuffer);
                const url = URL.createObjectURL(blob);
                preview.src = url;
                preview.style.display = 'block';

                // Download link
                downloadLink.href = url;
                downloadLink.download = 'processed_voip_audio.wav';
                downloadLink.textContent = 'Download Processed Audio (WAV)';
                downloadLink.style.display = 'block';

                status.textContent = 'Processing complete! Preview below and download.';
            } catch (err) {
                error.textContent = 'Error processing audio: ' + err.message;
                status.textContent = '';
            }
        });

        // Helper functions (unchanged from original)
        function toMono(buffer) {
            if (buffer.numberOfChannels === 1) return buffer;
            const monoBuffer = new AudioBuffer({
                length: buffer.length,
                numberOfChannels: 1,
                sampleRate: buffer.sampleRate
            });
            const left = buffer.getChannelData(0);
            const right = buffer.getChannelData(1);
            const monoData = monoBuffer.getChannelData(0);
            for (let i = 0; i < buffer.length; i++) {
                monoData[i] = (left[i] + right[i]) / 2;
            }
            return monoBuffer;
        }

        function audioBufferToWav(buffer) {
            return new Promise((resolve) => {
                const numChannels = buffer.numberOfChannels;
                const sampleRate = buffer.sampleRate;
                const length = buffer.length * numChannels * 2 + 44;
                const wavBuffer = new ArrayBuffer(length);
                const view = new DataView(wavBuffer);

                writeString(view, 0, 'RIFF');
                view.setUint32(4, 36 + buffer.length * numChannels * 2, true);
                writeString(view, 8, 'WAVE');
                writeString(view, 12, 'fmt ');
                view.setUint32(16, 16, true);
                view.setUint16(20, 1, true); // PCM
                view.setUint16(22, numChannels, true);
                view.setUint32(24, sampleRate, true);
                view.setUint32(28, sampleRate * numChannels * 2, true);
                view.setUint16(32, numChannels * 2, true);
                view.setUint16(34, 16, true); // 16-bit
                writeString(view, 36, 'data');
                view.setUint32(40, buffer.length * numChannels * 2, true);

                let offset = 44;
                for (let i = 0; i < buffer.length; i++) {
                    for (let channel = 0; channel < numChannels; channel++) {
                        const sample = Math.max(-1, Math.min(1, buffer.getChannelData(channel)[i]));
                        view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
                        offset += 2;
                    }
                }

                resolve(new Blob([wavBuffer], { type: 'audio/wav' }));
            });
        }

        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }
    </script>
</body>
</html>